# BiasBuster_RagProject
# ğŸ›¡ï¸ Bias Buster  
![Python](https://img.shields.io/badge/Python-3.10%2B-blue)  
![OpenAI](https://img.shields.io/badge/OpenAI-API-orange)  
![LangChain](https://img.shields.io/badge/LangChain-Framework-purple)  

Bias Buster is an AI-powered tool that detects and explains potential bias in text, datasets, and AI-generated outputs.  
It leverages **LangChain**, **ChromeDB**, and **OpenAI** to provide transparent, contextual bias analysis for journalists, researchers, and organizations.

---

## ğŸ“Œ Features
- ğŸ” **Bias Detection** â€“ Identify political, gender, racial, cultural, and other biases in text.
- ğŸ§  **Contextual Explanations** â€“ Understand *why* the text may be biased.
- ğŸ“‚ **Search & History** â€“ Store and query past analyses using ChromeDB.
- âš™ï¸ **Customizable Prompts** â€“ Fine-tune detection rules per domain.
- ğŸ“Š **Multiple Bias Categories** â€“ Detect implicit, explicit, and statistical bias.
- ğŸ” **Debug Content** - Debug the false Information generated by LLMS
---

## ğŸ› ï¸ Tech Stack
- **[LangChain](https://www.langchain.com/)** â€“ LLM orchestration
- **[ChromeDB](https://chromadb.com/)** â€“ Vector database for storage & retrieval
- **[OpenAI API](https://platform.openai.com/)** â€“ Text understanding & analysis
- - **[Streamlit](https://streamlit.io/)** â€“ Interactive web-based user interface
- **Python 3.10+**

## ğŸ“‚ How to use

1ï¸âƒ£ **Clone the repository
git clone https://github.com/Areeba-Tahir-18/BiasBuster_RagProject.git
cd bias-buster


2ï¸âƒ£ Create a virtual environment
python -m venv venv
source venv/bin/activate   # macOS/Linux
venv\Scripts\activate      # Windows


3ï¸âƒ£ Install dependencies
pip install -r requirements.txt


4ï¸âƒ£ Set environment variables
Create a .env file in the root directory
OPENAI_API_KEY=your_openai_api_key
CHROMADB_PATH=./chroma_storage

â–¶ï¸ Usage
Run the main script:

 src/app.py
Example interaction:





