# BiasBuster_RagProject
# ğŸ›¡ï¸ Bias Buster  
![Python](https://img.shields.io/badge/Python-3.10%2B-blue)  
![OpenAI](https://img.shields.io/badge/OpenAI-API-orange)  
![LangChain](https://img.shields.io/badge/LangChain-Framework-purple)  

Bias Buster is an AI-powered tool that detects and explains potential bias in text, datasets, and AI-generated outputs.  
It leverages **LangChain**, **ChromeDB**, and **OpenAI** to provide transparent, contextual bias analysis for journalists, researchers, and organizations.

---

## ğŸ“Œ Features
- ğŸ” **Bias Detection** â€“ Identify political, gender, racial, cultural, and other biases in text.
- ğŸ§  **Contextual Explanations** â€“ Understand *why* the text may be biased.
- ğŸ“‚ **Search & History** â€“ Store and query past analyses using ChromeDB.
- âš™ï¸ **Customizable Prompts** â€“ Fine-tune detection rules per domain.
- ğŸ“Š **Multiple Bias Categories** â€“ Detect implicit, explicit, and statistical bias.

---

## ğŸ› ï¸ Tech Stack
- **[LangChain](https://www.langchain.com/)** â€“ LLM orchestration
- **[ChromeDB](https://chromadb.com/)** â€“ Vector database for storage & retrieval
- **[OpenAI API](https://platform.openai.com/)** â€“ Text understanding & analysis
- **Python 3.10+**

## ğŸ“‚ Project Structure
bias-buster/
â”‚
â”œâ”€â”€ data/ # Sample datasets for testing
â”œâ”€â”€ notebooks/ # Jupyter notebooks for experiments
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ main.py # Main script to run the tool
â”‚ â”œâ”€â”€ analyzer.py # Bias detection logic
â”‚ â”œâ”€â”€ storage.py # ChromeDB interaction
â”‚ â””â”€â”€ prompts.py # Prompt templates for OpenAI
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ .env.example # Example environment variables

1ï¸âƒ£ **Clone the repository
git clone https://github.com/Areeba-Tahir-18/BiasBuster_RagProject.git
cd bias-buster


2ï¸âƒ£ Create a virtual environment
python -m venv venv
source venv/bin/activate   # macOS/Linux
venv\Scripts\activate      # Windows


3ï¸âƒ£ Install dependencies
pip install -r requirements.txt


4ï¸âƒ£ Set environment variables
Create a .env file in the root directory
OPENAI_API_KEY=your_openai_api_key
CHROMADB_PATH=./chroma_storage

â–¶ï¸ Usage
Run the main script:

 src/app.py
Example interaction:


Enter your text: Women are bad drivers.
[Bias Buster Output] ğŸš¨ Gender bias detected.
Explanation: This statement generalizes a negative stereotype about women without evidence.
ğŸ“Š Example Output
Input Text	Bias Type	Explanation
"Immigrants take our jobs."	Cultural/Ethnic Bias	Generalizes an entire group and attributes economic issues without context.
"The president is a genius."	Positive Bias	Overly positive sentiment without factual basis.
"All teenagers are lazy."	Age Bias	Assumes negative traits about all young people.




